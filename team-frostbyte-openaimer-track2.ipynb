{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11370963,"sourceType":"datasetVersion","datasetId":7118396},{"sourceId":342374,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":286409,"modelId":307239},{"sourceId":342382,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":286416,"modelId":307246}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nfrom torchvision.models import resnet18\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.optim as optim\nfrom collections import Counter\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:53:02.841905Z","iopub.execute_input":"2025-04-17T16:53:02.842299Z","iopub.status.idle":"2025-04-17T16:53:02.847595Z","shell.execute_reply.started":"2025-04-17T16:53:02.842271Z","shell.execute_reply":"2025-04-17T16:53:02.846663Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Data transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # standard ImageNet values\n                         std=[0.229, 0.224, 0.225])\n])\n\ndata_path = \"/kaggle/input/openaimer-2025-track-2-training-data\"\n\nfull_dataset = ImageFolder(root=data_path, transform=transform)\n\n# Train/val split \ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n\ntargets = [full_dataset.targets[i] for i in train_dataset.indices]\n\nclass_counts = Counter(targets)\nclass_weights = {cls: 1.0 / count for cls, count in class_counts.items()}\n\nsample_weights = [class_weights[label] for label in targets]\n\nsampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)  # Note: no shuffle\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nnum_classes = len(full_dataset.classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:58:04.796776Z","iopub.execute_input":"2025-04-17T16:58:04.797524Z","iopub.status.idle":"2025-04-17T17:00:11.097389Z","shell.execute_reply.started":"2025-04-17T16:58:04.797495Z","shell.execute_reply":"2025-04-17T17:00:11.096654Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:02:52.676626Z","iopub.execute_input":"2025-04-17T17:02:52.677060Z","iopub.status.idle":"2025-04-17T17:02:52.680525Z","shell.execute_reply.started":"2025-04-17T17:02:52.677036Z","shell.execute_reply":"2025-04-17T17:02:52.679775Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"model = resnet18(pretrained=True)  \nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T08:31:02.256532Z","iopub.execute_input":"2025-04-14T08:31:02.257027Z","iopub.status.idle":"2025-04-14T08:31:03.023806Z","shell.execute_reply.started":"2025-04-14T08:31:02.257001Z","shell.execute_reply":"2025-04-14T08:31:03.023067Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 199MB/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def train(model, loader):\n    model.train()\n    for epoch in range(10):\n        total_loss = 0\n        loop = tqdm(loader, desc=f\"Epoch [{epoch+1}/10]\")\n        for images, labels in loop:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            loop.set_postfix(loss=loss.item())\n\n        print(f\">>> Epoch {epoch+1} finished. Total Loss: {total_loss:.4f}\\n\")\ntrain(model, train_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T08:31:16.331434Z","iopub.execute_input":"2025-04-14T08:31:16.332177Z","iopub.status.idle":"2025-04-14T08:59:19.530002Z","shell.execute_reply.started":"2025-04-14T08:31:16.332152Z","shell.execute_reply":"2025-04-14T08:59:19.529242Z"}},"outputs":[{"name":"stderr","text":"Epoch [1/10]: 100%|██████████| 1000/1000 [03:32<00:00,  4.70it/s, loss=0.307]\n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 1 finished. Total Loss: 624.9473\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch [2/10]: 100%|██████████| 1000/1000 [03:15<00:00,  5.11it/s, loss=0.413]\n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 2 finished. Total Loss: 414.5704\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch [3/10]: 100%|██████████| 1000/1000 [03:01<00:00,  5.52it/s, loss=0.242]\n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 3 finished. Total Loss: 339.4634\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch [4/10]: 100%|██████████| 1000/1000 [02:50<00:00,  5.85it/s, loss=0.597] \n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 4 finished. Total Loss: 315.4203\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch [5/10]: 100%|██████████| 1000/1000 [02:41<00:00,  6.17it/s, loss=0.43]  \n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 5 finished. Total Loss: 272.5950\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch [6/10]: 100%|██████████| 1000/1000 [02:38<00:00,  6.32it/s, loss=0.37]  \n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 6 finished. Total Loss: 239.1609\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch [7/10]: 100%|██████████| 1000/1000 [02:34<00:00,  6.48it/s, loss=0.0858] \n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 7 finished. Total Loss: 231.1752\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch [8/10]: 100%|██████████| 1000/1000 [02:31<00:00,  6.61it/s, loss=0.0759]\n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 8 finished. Total Loss: 208.8075\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch [9/10]: 100%|██████████| 1000/1000 [02:28<00:00,  6.73it/s, loss=0.0522] \n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 9 finished. Total Loss: 177.9402\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch [10/10]: 100%|██████████| 1000/1000 [02:27<00:00,  6.76it/s, loss=0.00584]","output_type":"stream"},{"name":"stdout","text":">>> Epoch 10 finished. Total Loss: 164.3367\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"torch.save(model.state_dict(), \"resnet18_teacher.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T09:00:18.369510Z","iopub.execute_input":"2025-04-14T09:00:18.369792Z","iopub.status.idle":"2025-04-14T09:00:18.445174Z","shell.execute_reply.started":"2025-04-14T09:00:18.369770Z","shell.execute_reply":"2025-04-14T09:00:18.444581Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def validate(model, val_loader):\n    model.eval()  \n    correct = 0\n    total = 0\n    with torch.no_grad():  \n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T06:54:25.105773Z","iopub.execute_input":"2025-04-14T06:54:25.106354Z","iopub.status.idle":"2025-04-14T06:54:25.111120Z","shell.execute_reply.started":"2025-04-14T06:54:25.106331Z","shell.execute_reply":"2025-04-14T06:54:25.110409Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"validate(model, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T06:54:28.239759Z","iopub.execute_input":"2025-04-14T06:54:28.240013Z","iopub.status.idle":"2025-04-14T06:55:43.879262Z","shell.execute_reply.started":"2025-04-14T06:54:28.239995Z","shell.execute_reply":"2025-04-14T06:55:43.878696Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 78.78%\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"78.775"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"# Compression Processes","metadata":{}},{"cell_type":"code","source":"!pip install torch-pruning","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T09:48:48.973425Z","iopub.execute_input":"2025-04-14T09:48:48.973967Z","iopub.status.idle":"2025-04-14T09:49:59.066352Z","shell.execute_reply.started":"2025-04-14T09:48:48.973941Z","shell.execute_reply":"2025-04-14T09:49:59.065276Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting torch-pruning\n  Downloading torch_pruning-1.5.2-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-pruning) (2.5.1+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-pruning) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-pruning) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-pruning) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-pruning) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-pruning) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-pruning) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-pruning) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torch-pruning)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->torch-pruning)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->torch-pruning)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->torch-pruning)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torch-pruning)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torch-pruning)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torch-pruning)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-pruning) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-pruning) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-pruning) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-pruning) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-pruning) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-pruning) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-pruning) (2024.2.0)\nDownloading torch_pruning-1.5.2-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-pruning\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-pruning-1.5.2\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch_pruning as tp\nfrom torchvision.models import resnet18\n\nmodel = resnet18(pretrained=False)\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\nmodel.load_state_dict(torch.load(\"/kaggle/working/resnet18_teacher.pth\"))\nmodel.eval()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nexample_inputs = torch.randn(1, 3, 224, 224).to(device)\n\nimp = tp.importance.MagnitudeImportance(p=2)  \npruner = tp.pruner.MagnitudePruner(\n    model,\n    example_inputs=example_inputs,\n    importance=imp,\n    iterative_steps=1,   \n    pruning_ratio=0.3,   \n    ignored_layers=[model.fc],  \n)\n\n# Prune!\npruner.step()\n\ntorch.save(model, \"resnet18_pruned_actual.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T09:55:49.903722Z","iopub.execute_input":"2025-04-14T09:55:49.904395Z","iopub.status.idle":"2025-04-14T09:55:50.265584Z","shell.execute_reply.started":"2025-04-14T09:55:49.904373Z","shell.execute_reply":"2025-04-14T09:55:50.264633Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2561685082.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"/kaggle/working/resnet18_teacher.pth\"))\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"model = torch.load(\"/kaggle/working/resnet18_pruned_actual.pth\")\nmodel = model.to(device)\n\n# Criterion and optimizer for fine-tuning\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # Lower LR for fine-tuning\n\n# Fine-tuning function\ndef finetune(model, loader, epochs=10):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        correct, total = 0, 0\n        loop = tqdm(loader, desc=f\"Fine-tune Epoch [{epoch+1}/{epochs}]\")\n        for images, labels in loop:\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n            loop.set_postfix(loss=loss.item(), acc=100. * correct / total)\n\n        print(f\">>> Epoch {epoch+1}: Loss = {total_loss:.4f}, Accuracy = {100. * correct / total:.2f}%\\n\")\n\nfinetune(model, train_loader, epochs=5)\n\ntorch.save(model.state_dict(), \"resnet18_pruned_actual_finetuned.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T09:56:09.538377Z","iopub.execute_input":"2025-04-14T09:56:09.538640Z","iopub.status.idle":"2025-04-14T10:06:56.171786Z","shell.execute_reply.started":"2025-04-14T09:56:09.538621Z","shell.execute_reply":"2025-04-14T10:06:56.171074Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/473569755.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(\"/kaggle/working/resnet18_pruned_actual.pth\")\nFine-tune Epoch [1/5]: 100%|██████████| 1000/1000 [02:11<00:00,  7.60it/s, acc=95.1, loss=0.113] \n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 1: Loss = 164.8191, Accuracy = 95.13%\n\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch [2/5]: 100%|██████████| 1000/1000 [02:09<00:00,  7.74it/s, acc=97.3, loss=0.111] \n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 2: Loss = 97.4809, Accuracy = 97.29%\n\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch [3/5]: 100%|██████████| 1000/1000 [02:08<00:00,  7.79it/s, acc=97.9, loss=0.175]  \n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 3: Loss = 74.1831, Accuracy = 97.90%\n\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch [4/5]: 100%|██████████| 1000/1000 [02:07<00:00,  7.85it/s, acc=98.3, loss=0.00498]\n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 4: Loss = 62.7956, Accuracy = 98.29%\n\n","output_type":"stream"},{"name":"stderr","text":"Fine-tune Epoch [5/5]: 100%|██████████| 1000/1000 [02:09<00:00,  7.71it/s, acc=98.7, loss=0.0264] \n","output_type":"stream"},{"name":"stdout","text":">>> Epoch 5: Loss = 47.2883, Accuracy = 98.72%\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"torch.save(model, \"resnet18_pruned_actual_finetuned_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:09:05.973412Z","iopub.execute_input":"2025-04-14T10:09:05.973669Z","iopub.status.idle":"2025-04-14T10:09:06.019657Z","shell.execute_reply.started":"2025-04-14T10:09:05.973651Z","shell.execute_reply":"2025-04-14T10:09:06.019006Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = torch.load(\"/kaggle/input/compressedmodel/pytorch/default/1/model.pth\")\nmodel = model.to(device)\nmodel.eval()  \n\ndef evaluate_model(model, val_loader, device):\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    accuracy = accuracy_score(all_labels, all_preds)\n    return accuracy\n\naccuracy = evaluate_model(model, val_loader, device)\nprint(f\"Validation Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T11:13:39.134082Z","iopub.execute_input":"2025-04-17T11:13:39.134410Z","iopub.status.idle":"2025-04-17T11:14:32.301090Z","shell.execute_reply.started":"2025-04-17T11:13:39.134387Z","shell.execute_reply":"2025-04-17T11:14:32.300386Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3713926258.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(\"/kaggle/input/compressedmodel/pytorch/default/1/model.pth\")\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 93.73%\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport time\nfrom torchvision import models\nfrom sklearn.metrics import accuracy_score\nfrom torch.utils.data import DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\noriginal_model = models.resnet18(pretrained=True)  \noriginal_model.fc = nn.Linear(original_model.fc.in_features, num_classes)\noriginal_model = original_model.to(device)\n\nstate_dict = torch.load(\"/kaggle/input/basemodel/pytorch/default/1/resnet18_teacher.pth\")\n\noriginal_model.load_state_dict(state_dict, strict=False)  \noriginal_model.eval()  \n\n# Load pruned model\npruned_model = torch.load(\"/kaggle/input/compressedmodel/pytorch/default/1/model.pth\")\npruned_model = pruned_model.to(device)\npruned_model.eval()\n\n# Evaluation function\ndef evaluate_model(model, val_loader, device):\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            # Forward pass\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            # Store predictions and true labels\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(all_labels, all_preds)\n    return accuracy\n\n# Measure inference time for original model\nstart_time = time.time()\noriginal_accuracy = evaluate_model(original_model, val_loader, device)\noriginal_inference_time = time.time() - start_time\n\n# Measure inference time for pruned model\nstart_time = time.time()\npruned_accuracy = evaluate_model(pruned_model, val_loader, device)\npruned_inference_time = time.time() - start_time\n\n# Model size comparison\noriginal_model_size = sum(p.numel() for p in original_model.parameters()) * 4 / (1024 ** 2)  # Size in MB\npruned_model_size = sum(p.numel() for p in pruned_model.parameters()) * 4 / (1024 ** 2)  # Size in MB\n\n# Print results\nprint(f\"Original Model Accuracy: {original_accuracy * 100:.2f}%\")\nprint(f\"Pruned Model Accuracy: {pruned_accuracy * 100:.2f}%\")\nprint(f\"Original Model Size: {original_model_size:.2f} MB\")\nprint(f\"Pruned Model Size: {pruned_model_size:.2f} MB\")\nprint(f\"Original Model Inference Time: {original_inference_time:.4f} seconds\")\nprint(f\"Pruned Model Inference Time: {pruned_inference_time:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T11:20:27.737589Z","iopub.execute_input":"2025-04-17T11:20:27.737915Z","iopub.status.idle":"2025-04-17T11:21:14.492025Z","shell.execute_reply.started":"2025-04-17T11:20:27.737892Z","shell.execute_reply":"2025-04-17T11:21:14.491405Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 203MB/s]\n/tmp/ipykernel_31/2694876211.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(\"/kaggle/input/basemodel/pytorch/default/1/resnet18_teacher.pth\")\n/tmp/ipykernel_31/2694876211.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  pruned_model = torch.load(\"/kaggle/input/compressedmodel/pytorch/default/1/model.pth\")\n","output_type":"stream"},{"name":"stdout","text":"Original Model Accuracy: 86.29%\nPruned Model Accuracy: 93.73%\nOriginal Model Size: 42.83 MB\nPruned Model Size: 20.97 MB\nOriginal Model Inference Time: 23.5036 seconds\nPruned Model Inference Time: 22.0461 seconds\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Save and Load model as state_dict","metadata":{}},{"cell_type":"code","source":"import torch\n\nmodel = torch.load('/kaggle/input/compressedmodel/pytorch/default/1/model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:54:27.776387Z","iopub.execute_input":"2025-04-17T16:54:27.777005Z","iopub.status.idle":"2025-04-17T16:54:28.348311Z","shell.execute_reply.started":"2025-04-17T16:54:27.776979Z","shell.execute_reply":"2025-04-17T16:54:28.347777Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3711211622.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load('/kaggle/input/compressedmodel/pytorch/default/1/model.pth')\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"torch.save(model.state_dict(), 'pruned_model_state_dict.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:54:40.155963Z","iopub.execute_input":"2025-04-17T16:54:40.156472Z","iopub.status.idle":"2025-04-17T16:54:40.200521Z","shell.execute_reply.started":"2025-04-17T16:54:40.156450Z","shell.execute_reply":"2025-04-17T16:54:40.199977Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:55:38.696590Z","iopub.execute_input":"2025-04-17T16:55:38.697310Z","iopub.status.idle":"2025-04-17T16:55:38.701896Z","shell.execute_reply.started":"2025-04-17T16:55:38.697284Z","shell.execute_reply":"2025-04-17T16:55:38.701185Z"}},"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 44, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(44, 89, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(89, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(44, 89, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(89, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(89, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(89, 179, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(179, 179, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(89, 179, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(179, 179, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(179, 179, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(179, 358, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(358, 358, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(179, 358, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(358, 358, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(358, 358, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=358, out_features=100, bias=True)\n)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, downsample=None):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n\n    def forward(self, x):\n        identity = x\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        if self.downsample is not None:\n            identity = self.downsample(x)\n        out += identity\n        return self.relu(out)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:56:22.656388Z","iopub.execute_input":"2025-04-17T16:56:22.656659Z","iopub.status.idle":"2025-04-17T16:56:22.663123Z","shell.execute_reply.started":"2025-04-17T16:56:22.656638Z","shell.execute_reply":"2025-04-17T16:56:22.662249Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class PrunedResNet(nn.Module):\n    def __init__(self, block=BasicBlock, num_classes=100):\n        super().__init__()\n        self.inplanes = 44\n\n        self.conv1 = nn.Conv2d(3, 44, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(44)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        self.layer1 = self._make_layer(block, 44, 2, stride=1)\n        self.layer2 = self._make_layer(block, 89, 2, stride=2)\n        self.layer3 = self._make_layer(block, 179, 2, stride=2)\n        self.layer4 = self._make_layer(block, 358, 2, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(358 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, blocks, stride):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        return self.fc(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T16:56:34.591970Z","iopub.execute_input":"2025-04-17T16:56:34.592705Z","iopub.status.idle":"2025-04-17T16:56:34.601010Z","shell.execute_reply.started":"2025-04-17T16:56:34.592677Z","shell.execute_reply":"2025-04-17T16:56:34.600225Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = PrunedResNet()\nmodel.load_state_dict(torch.load(\"/kaggle/working/pruned_model_state_dict.pth\", map_location=device, weights_only=True))\nmodel.to(device)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:24:55.447076Z","iopub.execute_input":"2025-04-17T17:24:55.447898Z","iopub.status.idle":"2025-04-17T17:24:55.548154Z","shell.execute_reply.started":"2025-04-17T17:24:55.447869Z","shell.execute_reply":"2025-04-17T17:24:55.547225Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"PrunedResNet(\n  (conv1): Conv2d(3, 44, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(44, 89, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(89, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(44, 89, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(89, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(89, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(89, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(89, 179, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(179, 179, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(89, 179, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(179, 179, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(179, 179, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(179, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(179, 358, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(358, 358, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(179, 358, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(358, 358, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(358, 358, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(358, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=358, out_features=100, bias=True)\n)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"pruned_accuracy = evaluate_model(model, val_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:25:00.371134Z","iopub.execute_input":"2025-04-17T17:25:00.371401Z","iopub.status.idle":"2025-04-17T17:25:33.899131Z","shell.execute_reply.started":"2025-04-17T17:25:00.371381Z","shell.execute_reply":"2025-04-17T17:25:33.898290Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"print(pruned_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:07:05.004486Z","iopub.execute_input":"2025-04-17T17:07:05.005132Z","iopub.status.idle":"2025-04-17T17:07:05.008959Z","shell.execute_reply.started":"2025-04-17T17:07:05.005104Z","shell.execute_reply":"2025-04-17T17:07:05.008093Z"}},"outputs":[{"name":"stdout","text":"0.939\n","output_type":"stream"}],"execution_count":21}]}